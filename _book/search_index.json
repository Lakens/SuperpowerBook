[
["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2019-09-11 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["intro.html", "Chapter 2 Introduction 2.1 Validation of Power in One-Way ANOVA 2.2 Two conditions", " Chapter 2 Introduction knitr::opts_chunk$set(echo = TRUE) nsims &lt;- 100 #set number of simulations require(mvtnorm, quietly = TRUE) require(MASS, quietly = TRUE) require(afex, quietly = TRUE) ## Registered S3 methods overwritten by &#39;car&#39;: ## method from ## influence.merMod lme4 ## cooks.distance.influence.merMod lme4 ## dfbeta.influence.merMod lme4 ## dfbetas.influence.merMod lme4 ## ************ ## Welcome to afex. For support visit: http://afex.singmann.science/ ## - Functions for ANOVAs: aov_car(), aov_ez(), and aov_4() ## - Methods for calculating p-values with mixed(): &#39;KR&#39;, &#39;S&#39;, &#39;LRT&#39;, and &#39;PB&#39; ## - &#39;afex_aov&#39; and &#39;mixed&#39; objects can be passed to emmeans() for follow-up tests ## - NEWS: library(&#39;emmeans&#39;) now needs to be called explicitly! ## - Get and set global package options with: afex_options() ## - Set orthogonal sum-to-zero contrasts globally: set_sum_contrasts() ## - For example analyses see: browseVignettes(&quot;afex&quot;) ## ************ ## ## Attaching package: &#39;afex&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmer require(emmeans, quietly = TRUE) require(ggplot2, quietly = TRUE) require(gridExtra, quietly = TRUE) require(reshape2, quietly = TRUE) require(pwr, quietly = TRUE) # Install functions from GitHub by running the code below: library(Superpower) 2.1 Validation of Power in One-Way ANOVA Using the formula also used in Albers &amp; Lakens (2018), we can determine the means that should yield a specified effect sizes (expressed in Cohen’s f). Eta-squared (identical to partial eta-squared for One-Way ANOVA’s) has benchmarks of .0099, .0588, and .1379 for small, medium, and large effect sizes (Cohen, 1988). Athough these benchmarks are quite random, and researchers should only use such benchmarks for power analyses as a last resort, we will demonstrate a-priori power analysis for these values. 2.2 Two conditions Imagine we aim to design a study to test the hypothesis that giving people a pet to take care of will increase their life satisfaction. We have a control condition, and a condition where people get a pet, and randomly assign participants to either condition. We can simulate a One-Way ANOVA with a specified alpha, sample size, and effect size, on see the statistical power we would have for the ANOVA and the follow-up comparisons. We expect pets to increase life-satisfaction compared to the control condition. Based on work by Pavot and Diener (1993) we believe that we can expect responses on the life-satifaction scale to have a mean of approximately 24 in our population, with a standard deviation of 6.4. We expect having a pet increases life satisfaction with approximately 2.2 scale points for participants who get a pet. 200 participants in total, with 100 participants in each condition. But before we proceed with the data collection, we examine the statistical power our design would have to detect the differences we predict. string &lt;- &quot;2b&quot; n &lt;- 100 # We are thinking of running 50 peope in each condition mu &lt;- c(24, 26.2) # Enter means in the order that matches the labels below. # In this case, control, cat, dog. sd &lt;- 6.4 labelnames &lt;- c(&quot;condition&quot;, &quot;control&quot;, &quot;pet&quot;) # # the label names should be in the order of the means specified above. design_result &lt;- ANOVA_design(design = string, n = n, mu = mu, sd = sd, labelnames = labelnames) alpha_level &lt;- 0.05 # You should think carefully about how to justify your alpha level. # We will give some examples later, but for now, use 0.05. ANOVA_power(design_result, alpha_level = alpha_level, nsims = nsims) ## Power and Effect sizes for ANOVA tests ## power effect_size ## anova_condition 68 0.03395 ## ## Power and Effect sizes for contrasts ## power effect_size ## p_condition_control_condition_pet 68 0.3417 The result shows that we have exactly the same power for the ANOVA, as we have for the t-test. This is because when there are only two groups, these tests are mathematically identical. In a study with 100 participants, we would have quite low power (around 67.7%). An ANOVA with 2 groups is identical to a t-test. For our example, Cohen’s d (the standardized mean difference) is 2.2/6.4, or d = 0.34375 for the difference between the control condition and pets, which we can use to easily compute the expected power for these simple comparisons using the pwr package. pwr.t.test(d = 2.2/6.4, n = 100, sig.level = 0.05, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;)$power ## [1] 0.6768572 We can also directly compute Cohen’s f from Cohen’s d for two groups, as Cohen (1988) describes, because f = 1/2d. So f = 0.5*0.34375 = 0.171875. And indeed, power analysis using the pwr package yields the same result using the pwr.anova.test as the power.t.test. K &lt;- 2 n &lt;- 100 f &lt;- 0.171875 pwr.anova.test(n = n, k = K, f = f, sig.level = alpha_level)$power ## [1] 0.6768572 This analysis tells us that running the study with 100 participants in each condition is too likely to not yield a significant test result, even if our expected pattern of differences is true. This is not optimal. Let’s mathematically explore which pattern of means we would need to expect to habe 90% power for the ANOVA with 50 participants in each group. We can use the pwr package in R to compute a sensitivity analysis that tells us the effect size, in Cohen’s f, that we are able to detect with 3 groups and 50 partiicpants in each group, in order to achive 90% power with an alpha level of 5%. K &lt;- 2 n &lt;- 100 sd &lt;- 6.4 r &lt;- 0 #Calculate f when running simulation f &lt;- pwr.anova.test(n = n, k = K, power = 0.9, sig.level = alpha_level)$f f ## [1] 0.2303587 This sensitivity analysis shows we have 90% power in our planned design to detect effects of Cohen’s f of 0.2303587. Benchmarks by Cohen (1988) for small, medium, and large Cohen’s f values are 0.1, 0.25, and 0.4, which correspond to eta-squared values of small (.0099), medium (.0588), and large (.1379), in line with d = .2, .5, or .8. So, at least based on these benchmarks, we have 90% power to detect effects that are slightly below a medium effect benchmark. f2 &lt;- f^2 ES &lt;- f2/(f2+1) ES ## [1] 0.0503911 Expressed in eta-squared, we can detect values of eta-squared = 0.05 or larger. mu &lt;- mu_from_ES(K = K, ES = ES) mu &lt;- mu * sd mu ## [1] -1.474295 1.474295 We can compute a pattern of means, given a standard deviation of 6.4, that would give us an effect size of f = 0.23, or eta-squared of 0.05. We should be able to accomplish this is the means are -1.474295 and 1.474295. We can use these values to confirm the ANOVA has 90% power. design_result &lt;- ANOVA_design(design = string, n = n, mu = mu, sd = sd, labelnames = labelnames) ANOVA_power(design_result, alpha_level = alpha_level, nsims = nsims) ## Power and Effect sizes for ANOVA tests ## power effect_size ## anova_condition 87 0.05266 ## ## Power and Effect sizes for contrasts ## power effect_size ## p_condition_control_condition_pet 87 0.4509 The simulation confirms that for the F-test for the ANOVA we have 90% power. This is also what g*power tells us what would happen based on a post-hoc power analysis with an f of 0.2303587, 2 groups, 200 participants in total (100 in each between subject condition), and an alpha of 5%. If we return to our expected means, how many participants do we need for sufficient power? Given the expected difference and standard deviation, d = 0.34375, and f = 0.171875. We can perform an a-priori power analysis for this simple case, which tells us we need 179 participants in each group (we can’t split people in parts, and thus always round a power analysis upward), or 358 in total. K &lt;- 2 power &lt;- 0.9 f &lt;- 0.171875 pwr.anova.test(power = power, k = K, f = f, sig.level = alpha_level) ## ## Balanced one-way analysis of variance power calculation ## ## k = 2 ## n = 178.8104 ## f = 0.171875 ## sig.level = 0.05 ## power = 0.9 ## ## NOTE: n is number in each group If we re-run the simulation with this sample size, we indeed have 90% power. string &lt;- &quot;2b&quot; n &lt;- 179 mu &lt;- c(24, 26.2) # Enter means in the order that matches the labels below. # In this case, control, pet. sd &lt;- 6.4 labelnames &lt;- c(&quot;condition&quot;, &quot;control&quot;, &quot;pet&quot;) # # the label names should be in the order of the means specified above. design_result &lt;- ANOVA_design(design = string, n = n, mu = mu, sd = sd, labelnames = labelnames) alpha_level &lt;- 0.05 power_result &lt;- ANOVA_power(design_result, alpha_level = alpha_level, nsims = nsims) ## Power and Effect sizes for ANOVA tests ## power effect_size ## anova_condition 87 0.02948 ## ## Power and Effect sizes for contrasts ## power effect_size ## p_condition_control_condition_pet 87 0.3346 We stored the result from the power analysis in an object. This allows us to request plots (which are not printed automatically) showing the p-value distribution. If we request power_result$plot1 we get the p-value distribution for the ANOVA: power_result$plot1 If we request power_result$plot2 we get the p-value distribution for the paired comparisons (in this case only one): power_result$plot2 "],
["literature.html", "Chapter 3 Literature", " Chapter 3 Literature Here is a review of existing methods. "],
["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter. "],
["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
