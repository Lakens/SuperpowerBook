# Power Curve
```{r include = FALSE}
load("data/powercurve_data.RData")
```

Power is calculated for a specific value of an effect size, alpha level, and sample size. Because you often do not know the true effect size, it often makes more sense to think of the power curve as a function of the size of the effect. Although power curves can be calculated based on simulations for any design, we will use the analytic solution to calculate the power of ANOVA designs because these calculations are much faster. The basic approach is to calculate power for a specific pattern of means, a specific effect size, a given alpha level, and a specific pattern of correlations. This is one example:

```{r}
#2x2 design
string = "2w*2w"
mu = c(0,0,0,0.5)
n <- 20
sd <- 1
r <- 0.5
labelnames = c("A", "a1", "a2", "B", "b1", "b2")

design_result <- ANOVA_design(design = string,
                              n = n, 
                              mu = mu, 
                              sd = sd, 
                              r = r, 
                              labelnames = labelnames)

exact_result <- ANOVA_exact(design_result,
                            alpha_level = alpha_level,
                            verbose = FALSE)
```

```{r echo=FALSE}
knitr::kable(exact_result$main_results,
             caption = "Exact ANOVA Result")%>%
  kable_styling(latex_options = "hold_position")
```

We can make these calculations for a range of sample sizes, to get a power curve. We created a simple function that performs these calculations across a range of sample sizes (from n = 3 to max_, a variable you can specify in the function). 

```{r}
p_a <- plot_power(design_result,
                      max_n = 50)
p_a$plot_ANOVA
```

## Explore increase in effect size for moderated interactions.

The design has means 0, 0, 0, 0, with one cell increasing by 0.1, up to 0, 0, 0, 0.5. The standard deviation is set to 1. The correlation between all variables is 0.5. 

```{r, fig.height = 7, fig.width = 7, echo = FALSE}
plot1
```

## Explore increase in effect size for cross-over interactions.

The design has means 0, 0, 0, 0, with two cells increasing by 0.1, up to 0.5, 0, 0, 0.5. The standard deviation is set to 1. The correlation between all variables is 0.5. 

```{r, fig.height = 7, fig.width = 7, echo = FALSE}
plot2
```

## Explore increase in correlation in moderated interactions.

The design has means 0, 0, 0, 0.3. The standard deviation is set to 1. The correlation between all variables increases from 0 to 0.9. 

```{r, fig.height = 7, fig.width = 7, echo = FALSE}
plot3
```

## Increasing correlation in on factor decreases power in second factor
As Potvin and Schutz (2000) write: "The more important finding with respect to the effect of *r* on power relates to the effect of the correlations associated with one factor on the power of the test of the main effect of the other factor. Specifically, if the correlations among the levels of B are larger than those within the AB matrix (i.e., *r*B - *r*AB > 0.0), there is a reduction in the power for the test of the A effect (and the test on B is similarly affected by the A correlations)."
We see this in the plots below. As the correlation of the A factor increases from 0.4 to 0.9, we see the power for the main effect of factor B decreases.
```{r, fig.height = 7, fig.width = 7, echo = FALSE}
plot4
```
